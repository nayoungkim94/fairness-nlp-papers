# Fairness-NLP-Papers
Hi! Welcome to the Fairness in NLP Research Archive. This repository aims to provide researchers, practitioners, and students with easy access to influential and groundbreaking works that explore different aspects of fairness, including algorithmic bias, fairness metrics, mitigation techniques, and the societal implications of unfair practices. 

Author: [Nayoung Kim (Arizona State University)](https://nayoungkim94.github.io/)



## Contents
- Mitigate Bias
- Fairness Metrics
- Survey Papers

## Mitigate Bias

### Text Classification
- []()
- [Disentangling Dialect from Social Bias via Multitask Learning to Improve Fairness](https://arxiv.org/pdf/2406.09977), Splieth√∂ver, Maximilian, Sai Nikhil Menon, and Henning Wachsmuth, ACL 2024


-

### Generative AI

### Parameter-Efficient Debiasing
- [Parameter-efficient Modularised Bias Mitigation via AdapterFusion](https://arxiv.org/pdf/2302.06321), Deepak Kumar, Oleg Lesota, George Zerveas, Daniel Cohen, Carsten Eickhoff, Markus Schedl, Navid Rekabsaz, EACL 2023

- [PEFTDebias : Capturing debiasing information using PEFTs](https://arxiv.org/pdf/2312.00434), Sumit Agarwal, Aditya Srikanth Veerubhotla, Srijan Bansal, EMNLP 2023
- [An Empirical Analysis of Parameter-Efficient Methods for Debiasing Pre-Trained Language Models](https://arxiv.org/pdf/2306.04067), Zhongbin Xie, Thomas Lukasiewicz, ACL 2023
- [Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A Two-Stage Approach to Mitigate Social Biases](https://aclanthology.org/2023.acl-long.797.pdf), Yingji Li, Mengnan Du, Xin Wang, Ying Wang, ACL 2023
- [ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs](https://arxiv.org/pdf/2402.11764), Pengrui Han, Rafal Kocielnik, Adhithya Saravanan, Roy Jiang, Or Sharir, Anima Anandkumar, EACL 2024 Workshop on Language Technology for Equality, Diversity, Inclusion
- [The Trade-off between Performance, Efficiency, and Fairness in Adapter Modules for Text Classification](https://arxiv.org/pdf/2405.02010), Bui, Minh Duc, and Katharina von der Wense, NAACL 2024 4th Workshop on Trustworthy Natural Language Processing (TrustNLP)


## Fairness Metrics

### Statistical Fairness

### Causal Fairness
- [Addressing Both Statistical and Causal Gender Fairness in NLP Models](), Hannah Chen, Yangfeng Ji, David Evans, NAACL 2024 (Findings)

## Survey Papers

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE5MDYxMDg2MDddfQ==
-->
