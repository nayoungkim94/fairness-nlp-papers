# Fairness-NLP-Papers
Hi! Welcome to the Fairness in NLP Research Archive. This repository aims to provide researchers, practitioners, and students with easy access to influential and groundbreaking works that explore different aspects of fairness, including algorithmic bias, fairness metrics, mitigation techniques, and the societal implications of unfair practices. The papers are sorted in reverse chronological order.

Author: [Nayoung Kim (Arizona State University)](https://nayoungkim94.github.io/)



## Contents


### Mitigate Bias

**Text Classification**
- []()
-
-

**Generative AI**

**Parameter-Efficient Fine-Tuning (PEFT)**
- [Parameter-efficient Modularised Bias Mitigation via AdapterFusion]()
- [PEFTDebias : Capturing debiasing information using PEFTs]()


### Fairness Metrics




|                |ASCII                          |HTML                         |
|----------------|-------------------------------|-----------------------------|
|Single backticks|`'Isn't this fun?'`            |'Isn't this fun?'            |
|Quotes          |`"Isn't this fun?"`            |"Isn't this fun?"            |
|Dashes          |`-- is en-dash, --- is em-dash`|-- is en-dash, --- is em-dash|


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE5NTczMzM4OTFdfQ==
-->